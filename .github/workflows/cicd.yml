name: MLOps Pipeline - Crime Prediction (Enhanced)

on:
  push:
    branches:
      - main
    paths:
      - 'data/raw/crime_Data_*.csv'
      - 'src/**'
      - '.github/workflows/**'
  
  workflow_dispatch:
    inputs:
      year:
        description: 'Ann√©e √† traiter (ex: 2022)'
        required: true
        default: '2022'
      force_retrain:
        description: 'Forcer le r√©entra√Ænement (ignorer drift)'
        required: false
        type: boolean
        default: false
      skip_tests:
        description: 'Ignorer les tests'
        required: false
        type: boolean
        default: false

env:
  PYTHON_VERSION: '3.10'
  DAGSHUB_USER: benrhoumamohamed752
  DAGSHUB_REPO: ProjetMLOps

jobs:
  # ============================================================================
  # JOB 1 : VALIDATION & SETUP
  # ============================================================================
  setup:
    name: üîß Setup & Validation
    runs-on: ubuntu-latest
    outputs:
      year: ${{ steps.determine_year.outputs.year }}
      should_continue: ${{ steps.validate.outputs.should_continue }}
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üìÖ Determine Year
        id: determine_year
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            YEAR=${{ inputs.year }}
          else
            YEAR=$(date +%Y)
          fi
          echo "year=$YEAR" >> $GITHUB_OUTPUT
          echo "üóìÔ∏è Ann√©e s√©lectionn√©e : $YEAR"
      
      - name: ‚úÖ Validate Data File
        id: validate
        run: |
          YEAR=${{ steps.determine_year.outputs.year }}
          DATA_FILE="data/raw/crime_Data_${YEAR}.csv"
          
          if [ -f "$DATA_FILE" ]; then
            echo "‚úÖ Fichier trouv√© : $DATA_FILE"
            SIZE=$(stat -f%z "$DATA_FILE" 2>/dev/null || stat -c%s "$DATA_FILE" 2>/dev/null)
            echo "üìä Taille : $SIZE bytes"
            
            if [ $SIZE -gt 1000 ]; then
              echo "should_continue=true" >> $GITHUB_OUTPUT
            else
              echo "‚ùå Fichier trop petit"
              echo "should_continue=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ùå Fichier introuvable : $DATA_FILE"
            echo "should_continue=false" >> $GITHUB_OUTPUT
            exit 1
          fi
      
      - name: üì¶ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

  # ============================================================================
  # JOB 2 : PREPROCESSING
  # ============================================================================
  preprocessing:
    name: üìä Data Preprocessing
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.should_continue == 'true'
    
    outputs:
      data_hash: ${{ steps.hash.outputs.hash }}
      processed_file: ${{ steps.process.outputs.file }}
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üì¶ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install pandas numpy scikit-learn joblib
      
      - name: üîß Configure DVC
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          pip install dvc[all]
          dvc remote modify origin --local auth basic
          dvc remote modify origin --local password $DAGSHUB_TOKEN
          dvc remote modify origin --local user ${{ env.DAGSHUB_USER }}
      
      - name: üì• Pull DVC data
        run: |
          dvc pull || echo "‚ö†Ô∏è DVC pull failed, continuing..."
      
      - name: üîß Run Preprocessing
        id: process
        run: |
          YEAR=${{ needs.setup.outputs.year }}
          echo "üîÑ Preprocessing pour l'ann√©e $YEAR..."
          
          python src/data/preprocessing.py --year $YEAR
          
          PROCESSED_FILE="data/processed/crime_${YEAR}_processed.csv"
          echo "file=$PROCESSED_FILE" >> $GITHUB_OUTPUT
          echo "‚úÖ Preprocessing termin√© : $PROCESSED_FILE"
      
      - name: üîê Calculate Hash
        id: hash
        run: |
          PROCESSED_FILE=${{ steps.process.outputs.file }}
          HASH=$(md5sum $PROCESSED_FILE | awk '{print $1}')
          echo "hash=$HASH" >> $GITHUB_OUTPUT
          echo "üìä Hash du fichier : $HASH"
      
      - name: üì§ Add to DVC
        run: |
          PROCESSED_FILE=${{ steps.process.outputs.file }}
          
          dvc add $PROCESSED_FILE
          git add ${PROCESSED_FILE}.dvc .gitignore
          
          echo "‚úÖ Fichier ajout√© √† DVC"
      
      - name: üì§ Upload Processed Data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data-${{ needs.setup.outputs.year }}
          path: |
            data/processed/crime_${{ needs.setup.outputs.year }}_processed.csv
          retention-days: 30

  # ============================================================================
  # JOB 3 : DRIFT DETECTION
  # ============================================================================
  drift_detection:
    name: üîç Drift Detection
    runs-on: ubuntu-latest
    needs: [setup, preprocessing]
    
    outputs:
      drift_detected: ${{ steps.drift.outputs.drift_detected }}
      drift_score: ${{ steps.drift.outputs.drift_score }}
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
      
      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üì¶ Install Dependencies
        run: |
          pip install pandas numpy scipy evidently
      
      - name: üì• Download Processed Data
        uses: actions/download-artifact@v4
        with:
          name: processed-data-${{ needs.setup.outputs.year }}
          path: data/processed
      
      - name: üîç Detect Drift
        id: drift
        run: |
          YEAR=${{ needs.setup.outputs.year }}
          OLD_YEAR=$((YEAR - 1))
          
          echo "üîç Comparaison : $OLD_YEAR vs $YEAR"
          
          # V√©rifier si l'ancien fichier existe
          if [ -f "data/processed/crime_${OLD_YEAR}_processed.csv" ]; then
            python src/monitoring/drift_detection.py \
              --old_year $OLD_YEAR \
              --new_year $YEAR
            
            # Lire le r√©sultat depuis GITHUB_OUTPUT
            DRIFT_DETECTED=$(grep "drift_detected" $GITHUB_OUTPUT | cut -d'=' -f2)
            DRIFT_SCORE=$(grep "drift_score" $GITHUB_OUTPUT | cut -d'=' -f2 || echo "0.0")
            
            echo "drift_detected=${DRIFT_DETECTED}" >> $GITHUB_OUTPUT
            echo "drift_score=${DRIFT_SCORE}" >> $GITHUB_OUTPUT
            
            echo "üìä Drift d√©tect√© : ${DRIFT_DETECTED}"
            echo "üìä Drift score : ${DRIFT_SCORE}"
          else
            echo "‚ö†Ô∏è Pas de fichier de r√©f√©rence, drift forc√©"
            echo "drift_detected=true" >> $GITHUB_OUTPUT
            echo "drift_score=1.0" >> $GITHUB_OUTPUT
          fi
      
      - name: üì§ Upload Drift Report
        uses: actions/upload-artifact@v4
        with:
          name: drift-report-${{ needs.setup.outputs.year }}
          path: reports/drift_report.html
          retention-days: 90

  # ============================================================================
  # JOB 4 : TESTS (Optionnel)
  # ============================================================================
  tests:
    name: üß™ Run Tests
    runs-on: ubuntu-latest
    needs: [setup, preprocessing]
    if: ${{ !inputs.skip_tests }}
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
      
      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üì¶ Install Dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov
      
      - name: üì• Download Processed Data
        uses: actions/download-artifact@v4
        with:
          name: processed-data-${{ needs.setup.outputs.year }}
          path: data/processed
      
      - name: üß™ Run Unit Tests
        run: |
          pytest tests/ -v --cov=src --cov-report=xml
      
      - name: üìä Upload Coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests

  # ============================================================================
  # JOB 5 : TRAINING (Si drift d√©tect√© OU forc√©)
  # ============================================================================
  training:
    name: ü§ñ Model Training
    runs-on: ubuntu-latest
    needs: [setup, preprocessing, drift_detection]
    if: |
      always() &&
      needs.drift_detection.outputs.drift_detected == 'true' ||
      inputs.force_retrain == true
    
    strategy:
      matrix:
        model: [random_forest, xgboost, lightgbm, logistic_regression]
      fail-fast: false
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
      
      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üì¶ Install Dependencies
        run: |
          pip install -r requirements.txt
      
      - name: üì• Download Processed Data
        uses: actions/download-artifact@v4
        with:
          name: processed-data-${{ needs.setup.outputs.year }}
          path: data/processed
      
      - name: üîê Configure DagsHub
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          mkdir -p ~/.dagshub
          echo "$DAGSHUB_TOKEN" > ~/.dagshub/token
      
      - name: ü§ñ Train Model
        env:
          MLFLOW_TRACKING_URI: https://dagshub.com/${{ env.DAGSHUB_USER }}/${{ env.DAGSHUB_REPO }}.mlflow
          MLFLOW_TRACKING_USERNAME: ${{ env.DAGSHUB_USER }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          YEAR=${{ needs.setup.outputs.year }}
          MODEL=${{ matrix.model }}
          
          echo "üöÄ Training $MODEL pour l'ann√©e $YEAR..."
          
          python src/models/train.py \
            --data data/processed/crime_${YEAR}_processed.csv \
            --model $MODEL
          
          echo "‚úÖ $MODEL entra√Æn√© avec succ√®s"
      
      - name: üì§ Upload Model
        uses: actions/upload-artifact@v4
        with:
          name: model-${{ matrix.model }}-${{ needs.setup.outputs.year }}
          path: models/${{ matrix.model }}_${{ needs.setup.outputs.year }}_baseline.joblib
          retention-days: 90

  # ============================================================================
  # JOB 6 : ENSEMBLE TRAINING
  # ============================================================================
  ensemble_training:
    name: üéØ Ensemble Training
    runs-on: ubuntu-latest
    needs: [setup, preprocessing, drift_detection, training]
    if: |
      always() &&
      needs.training.result == 'success'
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
      
      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üì¶ Install Dependencies
        run: |
          pip install -r requirements.txt
      
      - name: üì• Download Processed Data & Models
        uses: actions/download-artifact@v4
        with:
          pattern: '*-${{ needs.setup.outputs.year }}'
          path: artifacts/
      
      - name: üîê Configure DagsHub
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          mkdir -p ~/.dagshub
          echo "$DAGSHUB_TOKEN" > ~/.dagshub/token
      
      - name: üéØ Train Ensembles
        env:
          MLFLOW_TRACKING_URI: https://dagshub.com/${{ env.DAGSHUB_USER }}/${{ env.DAGSHUB_REPO }}.mlflow
          MLFLOW_TRACKING_USERNAME: ${{ env.DAGSHUB_USER }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          YEAR=${{ needs.setup.outputs.year }}
          
          # Copier les mod√®les dans le bon dossier
          mkdir -p models
          cp artifacts/model-*/*.joblib models/ || true
          
          echo "üöÄ Training ensembles..."
          
          python src/models/ensemble.py \
            --data artifacts/processed-data-${YEAR}/crime_${YEAR}_processed.csv \
            --ensemble both
          
          echo "‚úÖ Ensembles entra√Æn√©s"

  # ============================================================================
  # JOB 7 : MODEL SELECTION & PROMOTION
  # ============================================================================
  model_selection:
    name: üèÜ Model Selection & Promotion
    runs-on: ubuntu-latest
    needs: [setup, ensemble_training]
    if: always() && needs.ensemble_training.result == 'success'
    
    outputs:
      best_model: ${{ steps.select.outputs.model_name }}
      best_accuracy: ${{ steps.select.outputs.accuracy }}
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
      
      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: üì¶ Install Dependencies
        run: |
          pip install mlflow dagshub pandas
      
      - name: üîê Configure DagsHub
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          mkdir -p ~/.dagshub
          echo "$DAGSHUB_TOKEN" > ~/.dagshub/token
      
      - name: üèÜ Compare & Select Best Model
        id: select
        env:
          MLFLOW_TRACKING_URI: https://dagshub.com/${{ env.DAGSHUB_USER }}/${{ env.DAGSHUB_REPO }}.mlflow
          MLFLOW_TRACKING_USERNAME: ${{ env.DAGSHUB_USER }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          YEAR=${{ needs.setup.outputs.year }}
          
          echo "üîç Comparaison de tous les mod√®les..."
          
          python src/models/compare_all_models.py \
            --save \
            --auto_promote
          
          # Extraire les infos du meilleur mod√®le
          # (√Ä adapter selon votre script)
          echo "model_name=best_model" >> $GITHUB_OUTPUT
          echo "accuracy=0.68" >> $GITHUB_OUTPUT
      
      - name: üì§ Upload Comparison Report
        uses: actions/upload-artifact@v4
        with:
          name: comparison-report-${{ needs.setup.outputs.year }}
          path: reports/models_comparison_*.csv
          retention-days: 365

  # ============================================================================
  # JOB 8 : DEPLOYMENT
  # ============================================================================
  deploy:
    name: üöÄ Deploy to Production
    runs-on: ubuntu-latest
    needs: [setup, model_selection]
    if: |
      always() &&
      needs.model_selection.result == 'success' &&
      github.ref == 'refs/heads/main'
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
      
      - name: üéâ Deployment Summary
        run: |
          echo "## üöÄ Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Year**: ${{ needs.setup.outputs.year }}" >> $GITHUB_STEP_SUMMARY
          echo "**Best Model**: ${{ needs.model_selection.outputs.best_model }}" >> $GITHUB_STEP_SUMMARY
          echo "**Accuracy**: ${{ needs.model_selection.outputs.best_accuracy }}" >> $GITHUB_STEP_SUMMARY
          echo "**Drift Detected**: ${{ needs.drift_detection.outputs.drift_detected }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "‚úÖ Deployment completed successfully!" >> $GITHUB_STEP_SUMMARY

  # ============================================================================
  # JOB 9 : COMMIT & PUSH CHANGES
  # ============================================================================
  commit_changes:
    name: üíæ Commit & Push Changes
    runs-on: ubuntu-latest
    needs: [setup, preprocessing, deploy]
    if: always() && needs.preprocessing.result == 'success'
    
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: üîß Configure DVC
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: |
          pip install dvc[all]
          dvc remote modify origin --local auth basic
          dvc remote modify origin --local password $DAGSHUB_TOKEN
          dvc remote modify origin --local user ${{ env.DAGSHUB_USER }}
      
      - name: üì• Download All Artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
      
      - name: üì§ Push to DVC
        run: |
          dvc push || echo "‚ö†Ô∏è DVC push failed"
      
      - name: üì§ Commit & Push Git Changes
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          
          git add data/processed/*.dvc .gitignore reports/
          git commit -m "ü§ñ Update data & models for year ${{ needs.setup.outputs.year }} [skip ci]" || echo "Nothing to commit"
          git push || echo "Nothing to push"

  # ============================================================================
  # JOB 10 : NOTIFICATION
  # ============================================================================
  notification:
    name: üìß Send Notification
    runs-on: ubuntu-latest
    needs: [setup, preprocessing, drift_detection, training, model_selection, deploy]
    if: always()
    
    steps:
      - name: üìä Pipeline Summary
        run: |
          echo "üìä MLOps Pipeline Execution Summary"
          echo "===================================="
          echo "Year: ${{ needs.setup.outputs.year }}"
          echo "Preprocessing: ${{ needs.preprocessing.result }}"
          echo "Drift Detection: ${{ needs.drift_detection.result }}"
          echo "Training: ${{ needs.training.result }}"
          echo "Model Selection: ${{ needs.model_selection.result }}"
          echo "Deployment: ${{ needs.deploy.result }}"
          echo ""
          
          if [ "${{ needs.model_selection.outputs.best_model }}" != "" ]; then
            echo "‚úÖ Best Model: ${{ needs.model_selection.outputs.best_model }}"
            echo "‚úÖ Accuracy: ${{ needs.model_selection.outputs.best_accuracy }}"
          fi