{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Validation Compl√®te avec DeepChecks - Crime Dataset 2020\n",
    "\n",
    "## üìã Table des Mati√®res\n",
    "1. [Niveau 1 : Int√©grit√© des Donn√©es](#niveau-1)\n",
    "2. [Niveau 2 : Drift et Distribution](#niveau-2)\n",
    "3. [Niveau 3 : Performance du Mod√®le](#niveau-3)\n",
    "4. [R√©sum√© et Recommandations](#resume)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installation des D√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation (si n√©cessaire)\n",
    "# !pip install deepchecks pandas scikit-learn joblib mlflow dagshub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# DeepChecks\n",
    "from deepchecks.tabular import Dataset\n",
    "from deepchecks.tabular.suites import (\n",
    "    data_integrity,\n",
    "    train_test_validation,\n",
    "    model_evaluation\n",
    ")\n",
    "\n",
    "# DeepChecks - Checks individuels\n",
    "from deepchecks.tabular.checks import (\n",
    "    # Int√©grit√© des donn√©es\n",
    "    MixedNulls,\n",
    "    MixedDataTypes,\n",
    "    StringMismatch,\n",
    "    DataDuplicates,\n",
    "    ConflictingLabels,\n",
    "    OutlierSampleDetection,\n",
    "    FeatureFeatureCorrelation,\n",
    "    FeatureLabelCorrelation,\n",
    "    \n",
    "    # Drift et Distribution\n",
    "    TrainTestFeatureDrift,\n",
    "    TrainTestLabelDrift,\n",
    "    WholeDatasetDrift,\n",
    "    FeatureDrift,\n",
    "    LabelDrift,\n",
    "    \n",
    "    # Performance du mod√®le\n",
    "    PerformanceReport,\n",
    "    ConfusionMatrixReport,\n",
    "    RocReport,\n",
    "    SimpleModelComparison,\n",
    "    CalibrationScore,\n",
    "    ModelInfo\n",
    ")\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Fonction de Mapping des Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_crime_group_4(desc):\n",
    "    \"\"\"Regroupe les crimes en 4 cat√©gories principales\"\"\"\n",
    "    if pd.isna(desc):\n",
    "        return \"Other / Fraud / Public Order Crime\"\n",
    "    desc = str(desc).upper()\n",
    "    \n",
    "    # Violent Crime\n",
    "    if any(k in desc for k in [\n",
    "        \"ASSAULT\", \"BATTERY\", \"ROBBERY\", \"HOMICIDE\",\n",
    "        \"MANSLAUGHTER\", \"KIDNAPPING\", \"CRIMINAL THREATS\",\n",
    "        \"INTIMATE PARTNER\", \"RAPE\", \"SEX\", \"SODOMY\",\n",
    "        \"ORAL COPULATION\", \"LEWD\", \"PORNOGRAPHY\",\n",
    "        \"FALSE IMPRISONMENT\"\n",
    "    ]):\n",
    "        return \"Violent Crime\"\n",
    "    \n",
    "    # Property & Theft Crime\n",
    "    if any(k in desc for k in [\n",
    "        \"THEFT\", \"BURGLARY\", \"SHOPLIFTING\",\n",
    "        \"VANDALISM\", \"ARSON\", \"PICKPOCKET\",\n",
    "        \"PURSE SNATCH\", \"TRESPASS\", \"BIKE\",\n",
    "        \"ILLEGAL DUMPING\"\n",
    "    ]):\n",
    "        return \"Property & Theft Crime\"\n",
    "    \n",
    "    # Vehicle-Related Crime\n",
    "    if any(k in desc for k in [\n",
    "        \"VEHICLE\", \"DWOC\", \"MOTOR VEHICLE\",\n",
    "        \"BOAT\"\n",
    "    ]):\n",
    "        return \"Vehicle-Related Crime\"\n",
    "    \n",
    "    return \"Other / Fraud / Public Order Crime\"\n",
    "\n",
    "print(\"‚úÖ Fonction de mapping d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ Chargement des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es\n",
    "print(\"üìÇ Chargement des donn√©es...\")\n",
    "df = pd.read_csv('data/processed/crime_2020_processed.csv')\n",
    "\n",
    "print(f\"\\nüìä Shape : {df.shape}\")\n",
    "print(f\"\\nüìã Colonnes disponibles :\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Appliquer le regroupement\n",
    "df['Crime_Group'] = df['Crm Cd Desc'].apply(map_crime_group_4)\n",
    "\n",
    "print(f\"\\n‚úÖ Donn√©es charg√©es : {len(df):,} lignes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Pr√©paration des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S√©lection des features\n",
    "feature_cols = ['Hour', 'Day_of_week', 'Month_num', 'LAT', 'LON', 'Vict Age', 'AREA']\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df['Crime_Group']\n",
    "\n",
    "# Encoder les labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"\\nüìä Features : {feature_cols}\")\n",
    "print(f\"\\nüè∑Ô∏è Classes d√©tect√©es :\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    count = (y == class_name).sum()\n",
    "    print(f\"   {i}. {class_name}: {count:,} ({count/len(y)*100:.2f}%)\")\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Split :\")\n",
    "print(f\"   Train : {X_train.shape}\")\n",
    "print(f\"   Test  : {X_test.shape}\")\n",
    "\n",
    "# Imputation\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(\n",
    "    imputer.fit_transform(X_train),\n",
    "    columns=feature_cols,\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_imputed = pd.DataFrame(\n",
    "    imputer.transform(X_test),\n",
    "    columns=feature_cols,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Imputation termin√©e\")\n",
    "print(f\"   NaN restants (train) : {X_train_imputed.isna().sum().sum()}\")\n",
    "print(f\"   NaN restants (test)  : {X_test_imputed.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Chargement du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le meilleur mod√®le (LightGBM)\n",
    "model_path = 'models/lightgbm_baseline.joblib'\n",
    "\n",
    "try:\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"‚úÖ Mod√®le charg√© : {model_path}\")\n",
    "    print(f\"   Type : {type(model).__name__}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ö†Ô∏è Mod√®le non trouv√© : {model_path}\")\n",
    "    print(\"   Veuillez d'abord entra√Æner le mod√®le avec :\")\n",
    "    print(\"   python src/models/train.py --model lightgbm\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Cr√©ation des Datasets DeepChecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les datasets DeepChecks\n",
    "train_dataset = Dataset(\n",
    "    X_train_imputed,\n",
    "    label=y_train,\n",
    "    cat_features=[],  # Pas de features cat√©gorielles (toutes num√©riques)\n",
    "    features=feature_cols\n",
    ")\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    X_test_imputed,\n",
    "    label=y_test,\n",
    "    cat_features=[],\n",
    "    features=feature_cols\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Datasets DeepChecks cr√©√©s\")\n",
    "print(f\"   Train : {len(train_dataset)} √©chantillons\")\n",
    "print(f\"   Test  : {len(test_dataset)} √©chantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <a id=\"niveau-1\"></a>üìä Niveau 1 : Int√©grit√© des Donn√©es\n",
    "\n",
    "V√©rification de la qualit√© des donn√©es : valeurs manquantes, duplicatas, outliers, coh√©rence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Suite Compl√®te d'Int√©grit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üîç NIVEAU 1 : INT√âGRIT√â DES DONN√âES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cr√©er la suite d'int√©grit√©\n",
    "integrity_suite = data_integrity()\n",
    "\n",
    "# Ex√©cuter sur le dataset d'entra√Ænement\n",
    "print(\"\\nüìä Ex√©cution de la suite d'int√©grit√© sur les donn√©es d'entra√Ænement...\")\n",
    "integrity_result = integrity_suite.run(train_dataset)\n",
    "\n",
    "# Afficher le r√©sultat\n",
    "integrity_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Checks Individuels D√©taill√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 - Valeurs Manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check des valeurs manquantes\n",
    "mixed_nulls_check = MixedNulls()\n",
    "result = mixed_nulls_check.run(train_dataset)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 - Duplicatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check des duplicatas\n",
    "duplicates_check = DataDuplicates()\n",
    "result = duplicates_check.run(train_dataset)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 - D√©tection d'Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©tection des outliers\n",
    "outlier_check = OutlierSampleDetection()\n",
    "result = outlier_check.run(train_dataset)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 - Corr√©lations Feature-Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corr√©lations entre features\n",
    "feature_correlation_check = FeatureFeatureCorrelation()\n",
    "result = feature_correlation_check.run(train_dataset)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 - Corr√©lations Feature-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corr√©lations feature-label\n",
    "label_correlation_check = FeatureLabelCorrelation()\n",
    "result = label_correlation_check.run(train_dataset)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - R√©sum√© Int√©grit√© des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã R√âSUM√â - INT√âGRIT√â DES DONN√âES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Statistiques g√©n√©rales\n",
    "print(f\"\\nüìä Statistiques g√©n√©rales :\")\n",
    "print(f\"   ‚Ä¢ Nombre d'√©chantillons : {len(X_train_imputed):,}\")\n",
    "print(f\"   ‚Ä¢ Nombre de features    : {len(feature_cols)}\")\n",
    "print(f\"   ‚Ä¢ Nombre de classes     : {len(le.classes_)}\")\n",
    "print(f\"   ‚Ä¢ Valeurs manquantes    : {X_train_imputed.isna().sum().sum()}\")\n",
    "print(f\"   ‚Ä¢ Duplicatas            : {X_train_imputed.duplicated().sum()}\")\n",
    "\n",
    "# Distribution des classes\n",
    "print(f\"\\nüè∑Ô∏è Distribution des classes (train) :\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    count = (y_train == i).sum()\n",
    "    percentage = count / len(y_train) * 100\n",
    "    print(f\"   {i}. {class_name:40} : {count:6,} ({percentage:5.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Niveau 1 termin√© !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <a id=\"niveau-2\"></a>üìà Niveau 2 : Drift et Distribution\n",
    "\n",
    "Comparaison des distributions entre train et test, d√©tection de drift.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Suite Compl√®te Train/Test Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìà NIVEAU 2 : DRIFT ET DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cr√©er la suite de validation train/test\n",
    "train_test_suite = train_test_validation()\n",
    "\n",
    "# Ex√©cuter\n",
    "print(\"\\nüìä Ex√©cution de la validation train/test...\")\n",
    "train_test_result = train_test_suite.run(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Afficher\n",
    "train_test_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Drift des Features (D√©taill√©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drift des features\n",
    "feature_drift_check = TrainTestFeatureDrift()\n",
    "result = feature_drift_check.run(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset\n",
    ")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Drift des Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drift des labels\n",
    "label_drift_check = TrainTestLabelDrift()\n",
    "result = label_drift_check.run(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset\n",
    ")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 - Analyse Statistique du Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse statistique d√©taill√©e du drift\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä ANALYSE STATISTIQUE DU DRIFT (Test de Kolmogorov-Smirnov)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "drift_results = []\n",
    "\n",
    "for feature in feature_cols:\n",
    "    # Test KS\n",
    "    statistic, p_value = ks_2samp(\n",
    "        X_train_imputed[feature], \n",
    "        X_test_imputed[feature]\n",
    "    )\n",
    "    \n",
    "    drift_detected = p_value < 0.05\n",
    "    \n",
    "    drift_results.append({\n",
    "        'Feature': feature,\n",
    "        'KS Statistic': statistic,\n",
    "        'P-Value': p_value,\n",
    "        'Drift D√©tect√©': 'üî¥ OUI' if drift_detected else '‚úÖ NON'\n",
    "    })\n",
    "\n",
    "df_drift = pd.DataFrame(drift_results)\n",
    "df_drift = df_drift.sort_values('KS Statistic', ascending=False)\n",
    "\n",
    "print(\"\\n\" + df_drift.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Compteur de drift\n",
    "n_drift = df_drift['Drift D√©tect√©'].str.contains('OUI').sum()\n",
    "print(f\"\\nüîç R√©sultat : {n_drift}/{len(feature_cols)} features avec drift d√©tect√©\")\n",
    "\n",
    "if n_drift > 0:\n",
    "    print(\"\\n‚ö†Ô∏è ATTENTION : Drift d√©tect√© !\")\n",
    "    print(\"   Le mod√®le pourrait avoir des performances d√©grad√©es.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Aucun drift significatif d√©tect√©.\")\n",
    "    print(\"   Les distributions train/test sont similaires.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 - Visualisations des Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les distributions train vs test\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(feature_cols):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Histogrammes\n",
    "    ax.hist(X_train_imputed[feature], bins=30, alpha=0.5, label='Train', density=True)\n",
    "    ax.hist(X_test_imputed[feature], bins=30, alpha=0.5, label='Test', density=True)\n",
    "    \n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Densit√©')\n",
    "    ax.legend()\n",
    "    ax.set_title(f'Distribution : {feature}')\n",
    "\n",
    "# Cacher le dernier subplot vide\n",
    "if len(feature_cols) < len(axes):\n",
    "    for i in range(len(feature_cols), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/deepchecks_distributions.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úÖ Graphique sauvegard√© : reports/deepchecks_distributions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <a id=\"niveau-3\"></a>üéØ Niveau 3 : Performance du Mod√®le\n",
    "\n",
    "√âvaluation compl√®te des performances du mod√®le sur le test set.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Pr√©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üéØ NIVEAU 3 : PERFORMANCE DU MOD√àLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if model is not None:\n",
    "    # Pr√©dictions\n",
    "    y_pred_train = model.predict(X_train_imputed)\n",
    "    y_pred_test = model.predict(X_test_imputed)\n",
    "    \n",
    "    # Probabilit√©s (si disponible)\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba_test = model.predict_proba(X_test_imputed)\n",
    "    else:\n",
    "        y_proba_test = None\n",
    "    \n",
    "    print(\"\\n‚úÖ Pr√©dictions g√©n√©r√©es\")\n",
    "    print(f\"   Train : {len(y_pred_train)} pr√©dictions\")\n",
    "    print(f\"   Test  : {len(y_pred_test)} pr√©dictions\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Aucun mod√®le charg√©, skip Niveau 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Suite Compl√®te d'√âvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "    # Cr√©er la suite d'√©valuation\n",
    "    model_eval_suite = model_evaluation()\n",
    "    \n",
    "    # Ex√©cuter\n",
    "    print(\"\\nüìä Ex√©cution de l'√©valuation du mod√®le...\")\n",
    "    model_eval_result = model_eval_suite.run(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    # Afficher\n",
    "    model_eval_result.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skip suite d'√©valuation (pas de mod√®le)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Rapport de Performance D√©taill√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "    performance_check = PerformanceReport()\n",
    "    result = performance_check.run(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        model=model\n",
    "    )\n",
    "    result.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skip performance report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 - Matrice de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "    confusion_matrix_check = ConfusionMatrixReport()\n",
    "    result = confusion_matrix_check.run(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        model=model\n",
    "    )\n",
    "    result.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skip confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 - M√©triques D√©taill√©es par Classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None:\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä M√âTRIQUES D√âTAILL√âES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # M√©triques globales\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    test_f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
    "    test_precision = precision_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_pred_test, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\nüéØ M√©triques Globales :\")\n",
    "    print(f\"   ‚Ä¢ Train Accuracy    : {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "    print(f\"   ‚Ä¢ Test Accuracy     : {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "    print(f\"   ‚Ä¢ Test F1-Score     : {test_f1:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Test Precision    : {test_precision:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Test Recall       : {test_recall:.4f}\")\n",
    "    \n",
    "    # Overfitting/Underfitting\n",
    "    gap = train_acc - test_acc\n",
    "    print(f\"\\nüìâ √âcart Train-Test : {gap:.4f} ({gap*100:.2f}%)\")\n",
    "    if gap > 0.1:\n",
    "        print(\"   ‚ö†Ô∏è OVERFITTING d√©tect√© !\")\n",
    "    elif gap < 0:\n",
    "        print(\"   ‚ö†Ô∏è UNDERFITTING d√©tect√© !\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Bon √©quilibre train/test\")\n",
    "    \n",
    "    # Rapport par classe\n",
    "    print(f\"\\nüìã Classification Report :\")\n",
    "    print(classification_report(\n",
    "        y_test, \n",
    "        y_pred_test, \n",
    "        target_names=le.classes_,\n",
    "        zero_division=0\n",
    "    ))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skip m√©triques d√©taill√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 - Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model is not None and hasattr(model, 'feature_importances_'):\n",
    "    # Feature importance\n",
    "    importances = model.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üåü FEATURE IMPORTANCE\")\n",
    "    print(\"=\"*80)\n",
    "    print(feature_importance_df.to_string(index=False))\n",
    "    \n",
    "    # Graphique\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Feature Importance - LightGBM')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('reports/deepchecks_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\n‚úÖ Graphique sauvegard√© : reports/deepchecks_feature_importance.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Feature importance non disponible pour ce mod√®le\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <a id=\"resume\"></a>üìã R√©sum√© et Recommandations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìã R√âSUM√â G√âN√âRAL - VALIDATION DEEPCHECKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìÖ Date : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üìä Dataset : crime_2020_processed.csv\")\n",
    "print(f\"ü§ñ Mod√®le : {type(model).__name__ if model else 'N/A'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ NIVEAU 1 : INT√âGRIT√â DES DONN√âES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   ‚Ä¢ √âchantillons       : {len(X_train_imputed):,}\")\n",
    "print(f\"   ‚Ä¢ Features           : {len(feature_cols)}\")\n",
    "print(f\"   ‚Ä¢ Valeurs manquantes : {X_train_imputed.isna().sum().sum()}\")\n",
    "print(f\"   ‚Ä¢ Duplicatas         : {X_train_imputed.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ NIVEAU 2 : DRIFT ET DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "if 'df_drift' in locals():\n",
    "    n_drift = df_drift['Drift D√©tect√©'].str.contains('OUI').sum()\n",
    "    print(f\"   ‚Ä¢ Features avec drift : {n_drift}/{len(feature_cols)}\")\n",
    "    if n_drift > 0:\n",
    "        print(\"   ‚ö†Ô∏è ATTENTION : Drift d√©tect√© sur certaines features\")\n",
    "        print(\"      ‚Üí Consid√©rer un r√©entra√Ænement avec donn√©es plus r√©centes\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Distributions train/test similaires\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ NIVEAU 3 : PERFORMANCE DU MOD√àLE\")\n",
    "print(\"=\"*80)\n",
    "if model is not None:\n",
    "    print(f\"   ‚Ä¢ Test Accuracy  : {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "    print(f\"   ‚Ä¢ Test F1-Score  : {test_f1:.4f}\")\n",
    "    print(f\"   ‚Ä¢ √âcart Train-Test : {gap:.4f}\")\n",
    "    \n",
    "    if gap > 0.1:\n",
    "        print(\"   ‚ö†Ô∏è Overfitting d√©tect√©\")\n",
    "    elif test_acc < 0.6:\n",
    "        print(\"   ‚ö†Ô∏è Performance mod√©r√©e (< 60%)\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ Performance acceptable\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Aucun mod√®le √©valu√©\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° RECOMMANDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Recommandations bas√©es sur les r√©sultats\n",
    "if model is not None and test_acc < 0.6:\n",
    "    recommendations.append(\"üìà Am√©liorer les performances (<60%) :\")\n",
    "    recommendations.append(\"   ‚Ä¢ Ajouter plus de features (temporelles, spatiales)\")\n",
    "    recommendations.append(\"   ‚Ä¢ Optimiser les hyperparam√®tres (GridSearch)\")\n",
    "    recommendations.append(\"   ‚Ä¢ Combiner avec donn√©es 2021 pour plus de samples\")\n",
    "\n",
    "if 'n_drift' in locals() and n_drift > 0:\n",
    "    recommendations.append(\"üîÑ Drift d√©tect√© :\")\n",
    "    recommendations.append(\"   ‚Ä¢ R√©entra√Æner le mod√®le avec donn√©es plus r√©centes\")\n",
    "    recommendations.append(\"   ‚Ä¢ Mettre en place monitoring continu du drift\")\n",
    "\n",
    "if model is not None and gap > 0.1:\n",
    "    recommendations.append(\"‚öñÔ∏è Overfitting d√©tect√© :\")\n",
    "    recommendations.append(\"   ‚Ä¢ Augmenter la r√©gularisation\")\n",
    "    recommendations.append(\"   ‚Ä¢ R√©duire la complexit√© du mod√®le\")\n",
    "    recommendations.append(\"   ‚Ä¢ Ajouter plus de donn√©es d'entra√Ænement\")\n",
    "\n",
    "recommendations.append(\"üöÄ Actions prioritaires :\")\n",
    "recommendations.append(\"   1. Promouvoir le meilleur mod√®le en production\")\n",
    "recommendations.append(\"   2. Mettre en place l'API et le monitoring\")\n",
    "recommendations.append(\"   3. Planifier r√©entra√Ænement p√©riodique\")\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(rec)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ VALIDATION DEEPCHECKS TERMIN√âE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä Rapports sauvegard√©s :\")\n",
    "print(\"   ‚Ä¢ reports/deepchecks_distributions.png\")\n",
    "if model is not None and hasattr(model, 'feature_importances_'):\n",
    "    print(\"   ‚Ä¢ reports/deepchecks_feature_importance.png\")\n",
    "\n",
    "print(\"\\nüíæ Pour sauvegarder les rapports HTML :\")\n",
    "print(\"   integrity_result.save_as_html('reports/deepchecks_integrity.html')\")\n",
    "print(\"   train_test_result.save_as_html('reports/deepchecks_train_test.html')\")\n",
    "if model is not None:\n",
    "    print(\"   model_eval_result.save_as_html('reports/deepchecks_model_eval.html')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Sauvegarder les Rapports HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le dossier reports s'il n'existe pas\n",
    "import os\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "\n",
    "# Sauvegarder les rapports HTML\n",
    "print(\"üíæ Sauvegarde des rapports HTML...\\n\")\n",
    "\n",
    "integrity_result.save_as_html('reports/deepchecks_integrity.html')\n",
    "print(\"   ‚úÖ reports/deepchecks_integrity.html\")\n",
    "\n",
    "train_test_result.save_as_html('reports/deepchecks_train_test.html')\n",
    "print(\"   ‚úÖ reports/deepchecks_train_test.html\")\n",
    "\n",
    "if model is not None:\n",
    "    model_eval_result.save_as_html('reports/deepchecks_model_eval.html')\n",
    "    print(\"   ‚úÖ reports/deepchecks_model_eval.html\")\n",
    "\n",
    "print(\"\\n‚úÖ Tous les rapports sont sauvegard√©s dans le dossier reports/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Validation Termin√©e !\n",
    "\n",
    "Vous pouvez maintenant :\n",
    "1. Consulter les rapports HTML dans `reports/`\n",
    "2. Analyser les r√©sultats d√©taill√©s\n",
    "3. Prendre des d√©cisions sur le r√©entra√Ænement\n",
    "4. Promouvoir le mod√®le en production si satisfaisant\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
