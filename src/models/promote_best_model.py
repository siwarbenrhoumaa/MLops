"""
Script de comparaison et promotion du meilleur mod√®le parmi ceux d'une m√™me ann√©e
Utilise le param√®tre 'year' logg√© dans MLflow pour filtrer
"""

import mlflow
import dagshub
from mlflow.tracking import MlflowClient
from mlflow.entities import ViewType
import pandas as pd
import argparse
import os

def connect_to_mlflow():
    # Les env vars sont d√©j√† configur√©es par le workflow
    tracking_uri = os.getenv('MLFLOW_TRACKING_URI')
    if tracking_uri:
        print(f"‚úÖ MLflow Tracking URI: {tracking_uri}")
    
    client = MlflowClient()
    return client

def get_models_by_year(client, target_year):
    """
    R√©cup√®re tous les runs contenant le param√®tre 'year' = target_year
    """
    print("=" * 130)
    print(f"üìä COMPARAISON DES MOD√àLES POUR L'ANN√âE {target_year}")
    print("=" * 130)

    # Tous les experiments possibles
    experiment_names = [
        'crime-prediction-baseline',
        'crime-prediction-ensemble'
    ]

    all_results = []

    for exp_name in experiment_names:
        experiment = client.get_experiment_by_name(exp_name)
        if not experiment:
            continue

        print(f"\nüîç Analyse de l'experiment : {exp_name}")

        runs = client.search_runs(
            experiment_ids=[experiment.experiment_id],
            run_view_type=ViewType.ACTIVE_ONLY,
            filter_string=f"params.year = '{target_year}'",
            order_by=["metrics.test_accuracy DESC"],
            max_results=100
        )

        print(f"   ‚Üí {len(runs)} runs trouv√©s pour l'ann√©e {target_year}")

        for run in runs:
            run_name = run.data.tags.get('mlflow.runName', 'N/A')
            model_type = run.data.params.get('model_type',
                                            run.data.params.get('ensemble_type', 'N/A'))

            test_acc = run.data.metrics.get('test_accuracy', 0)
            test_f1 = run.data.metrics.get('test_f1_weighted',
                                          run.data.metrics.get('test_f1', 0))
            cv_mean = run.data.metrics.get('cv_accuracy_mean', 0)
            cv_std = run.data.metrics.get('cv_accuracy_std', 0)
            train_acc = run.data.metrics.get('train_accuracy', 0)

            overfitting_gap = train_acc - test_acc if train_acc > 0 else 0

            all_results.append({
                'Type': 'Ensemble' if 'ensemble' in exp_name else 'Baseline',
                'Run Name': run_name,
                'Model': model_type,
                'Test Accuracy': test_acc,
                'Test F1': test_f1,
                'CV Mean': cv_mean,
                'CV Std': cv_std,
                'Train Acc': train_acc,
                'Overfitting Gap': overfitting_gap,
                'Run ID': run.info.run_id,
                'Created': run.info.start_time
            })

    if not all_results:
        print(f"\n‚ùå Aucun mod√®le trouv√© pour l'ann√©e {target_year} !")
        return None

    df = pd.DataFrame(all_results)
    df = df.sort_values('Test Accuracy', ascending=False).reset_index(drop=True)
    return df

# === Les fonctions d'affichage restent IDENTIQUES ===
# (display_comparison, display_top_3, display_best_model_details, display_statistics, recommend_action)
# ‚Üí Je les garde telles quelles pour conserver la structure

def display_comparison(df):
    print("\n" + "=" * 130)
    print("üèÜ CLASSEMENT DES MOD√àLES DE CETTE ANN√âE")
    print("=" * 130)
    
    print(f"\n{'Rank':<5} {'Type':<10} {'Model':<20} {'Run Name':<35} {'Test Acc':<12} {'Test F1':<10} {'CV Mean':<10} {'Overfit':<10}")
    print("-" * 130)
    
    for idx, row in df.iterrows():
        rank = idx + 1
        symbol = "ü•á" if rank == 1 else "ü•à" if rank == 2 else "ü•â" if rank == 3 else "  "
        overfit_symbol = "‚ö†Ô∏è" if row['Overfitting Gap'] > 0.05 else "‚úÖ"
        
        print(f"{symbol} {rank:<3} {row['Type']:<10} {row['Model']:<20} {row['Run Name'][:34]:<35} "
              f"{row['Test Accuracy']:<12.4f} {row['Test F1']:<10.4f} {row['CV Mean']:<10.4f} "
              f"{overfit_symbol} {row['Overfitting Gap']:<9.4f}")
    
    print("-" * 130)

def display_top_3(df):
    print("\n" + "=" * 130)
    print("üèÖ PODIUM - TOP 3 MOD√àLES")
    print("=" * 130)
    
    medals = ["ü•á", "ü•à", "ü•â"]
    positions = ["1er", "2√®me", "3√®me"]
    
    for i in range(min(3, len(df))):
        model = df.iloc[i]
        print(f"\n{medals[i]} {positions[i]} Place - {model['Model'].upper()}")
        print(f"   Type           : {model['Type']}")
        print(f"   Run Name       : {model['Run Name']}")
        print(f"   Test Accuracy  : {model['Test Accuracy']:.4f} ({model['Test Accuracy']*100:.2f}%)")
        print(f"   Test F1        : {model['Test F1']:.4f}")
        print(f"   CV Mean        : {model['CV Mean']:.4f}")
        print(f"   Stabilit√©      : {'‚úÖ Stable' if model['Overfitting Gap'] < 0.05 else '‚ö†Ô∏è Overfit'}")

def display_best_model_details(client, df):
    best = df.iloc[0]
    
    print("\n" + "=" * 130)
    print("üèÜ MEILLEUR MOD√àLE DE CETTE ANN√âE - D√âTAILS")
    print("=" * 130)
    
    print(f"\nüéØ Informations G√©n√©rales :")
    print(f"   ‚Ä¢ Rang             : #1 sur {len(df)} mod√®les")
    print(f"   ‚Ä¢ Type             : {best['Type']}")
    print(f"   ‚Ä¢ Mod√®le           : {best['Model']}")
    print(f"   ‚Ä¢ Run Name         : {best['Run Name']}")
    print(f"   ‚Ä¢ Run ID           : {best['Run ID']}")
    
    print(f"\nüìä M√©triques de Performance :")
    print(f"   ‚Ä¢ Test Accuracy    : {best['Test Accuracy']:.4f} ({best['Test Accuracy']*100:.2f}%)")
    print(f"   ‚Ä¢ Test F1-Score    : {best['Test F1']:.4f}")
    print(f"   ‚Ä¢ CV Mean          : {best['CV Mean']:.4f}")
    print(f"   ‚Ä¢ Train Accuracy   : {best['Train Acc']:.4f}")
    
    gap = best['Overfitting Gap']
    status = "‚ö†Ô∏è OVERFITTING" if gap > 0.1 else "‚ö†Ô∏è L√âGER OVERFIT" if gap > 0.05 else "‚úÖ STABLE"
    print(f"\n‚öñÔ∏è Stabilit√© : {status} (gap = {gap:.4f})")

def display_statistics(df):
    print("\n" + "=" * 130)
    print("üìà STATISTIQUES DE CETTE ANN√âE")
    print("=" * 130)
    
    print("\nüìä Moyennes par Type :")
    print(df.groupby('Type')['Test Accuracy'].agg(['mean', 'std', 'min', 'max', 'count']).round(4))
    
    print("\nüìä Moyennes par Mod√®le :")
    print(df.groupby('Model')['Test Accuracy'].agg(['mean', 'count']).round(4))

def recommend_action(df, year):
    best = df.iloc[0]
    print("\n" + "=" * 130)
    print("üí° RECOMMANDATION")
    print("=" * 130)
    print(f"\nüéØ Promouvoir : {best['Model'].upper()} ({best['Run Name']})")
    print(f"   Accuracy : {best['Test Accuracy']*100:.2f}%")

# === La fonction promote_best_model reste IDENTIQUE ===
# (je la garde telle quelle, elle fonctionne parfaitement)

def promote_best_model(client, best_run_info, model_name="crime-prediction-model", auto=False):
    """
    Promouvoir automatiquement le meilleur mod√®le en production
    """
    import tempfile
    import os
    import joblib
    from mlflow.models.signature import infer_signature
    
    run_id = best_run_info['Run ID']
    run_name = best_run_info['Run Name']
    model_type = best_run_info['Model']
    accuracy = best_run_info['Test Accuracy']
    
    print("\n" + "=" * 130)
    print("üöÄ PROMOTION EN PRODUCTION")
    print("=" * 130)
    
    print(f"\nüéØ Mod√®le s√©lectionn√© :")
    print(f"   ‚Ä¢ Nom           : {model_type.upper()}")
    print(f"   ‚Ä¢ Run Name      : {run_name}")
    print(f"   ‚Ä¢ Accuracy      : {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   ‚Ä¢ Run ID        : {run_id}")
    
    # Confirmation si pas auto
    if not auto:
        print(f"\n‚ö†Ô∏è  Voulez-vous promouvoir ce mod√®le en production ?")
        confirm = input("   Confirmer (o/n) ? : ").strip().lower()
        if confirm != 'o':
            print("‚ùå Promotion annul√©e")
            return False
    
    try:
        # 1. Trouver le fichier .joblib
        print(f"\nüì• √âtape 1/4 : Recherche du mod√®le...")
        artifacts = client.list_artifacts(run_id)
        
        joblib_files = [art.path for art in artifacts if art.path.endswith('.joblib')]
        
        if not joblib_files:
            print("‚ùå Aucun fichier .joblib trouv√©")
            return False
        
        # Prioriser certains fichiers
        priority = ['stacking', 'voting', 'ensemble', 'baseline', 'artifacts']
        joblib_path = None
        for p in priority:
            for path in joblib_files:
                if p in path.lower():
                    joblib_path = path
                    break
            if joblib_path:
                break
        
        if not joblib_path:
            joblib_path = joblib_files[0]
        
        print(f"   ‚úÖ Mod√®le trouv√© : {joblib_path}")
        
        # 2. T√©l√©charger et charger le mod√®le
        print(f"\nüì• √âtape 2/4 : Chargement du mod√®le...")
        with tempfile.TemporaryDirectory() as tmpdir:
            local_path = client.download_artifacts(run_id, joblib_path, dst_path=tmpdir)
            full_path = os.path.join(tmpdir, joblib_path)
            
            # Charger le mod√®le
            if full_path.endswith('_artifacts.joblib'):
                artifacts_bundle = joblib.load(full_path)
                model = artifacts_bundle.get('model', artifacts_bundle)
            else:
                model = joblib.load(full_path)
            
            print(f"   ‚úÖ Mod√®le charg√© : {type(model).__name__}")
            
            # 3. Cr√©er input example et signature
            print(f"\nüîß √âtape 3/4 : Pr√©paration de la signature...")
            
            # R√©cup√©rer les features du run original
            original_run = client.get_run(run_id)
            features_param = original_run.data.params.get('features', '')
            
            # Cr√©er un input example
            dummy_input = pd.DataFrame({
                'Hour': [12],
                'Day_of_week': [3],
                'Month_num': [6],
                'LAT': [34.05],
                'LON': [-118.25],
                'Vict Age': [35.0],
                'AREA': [15]
            })
            
            # Ajouter colonnes optionnelles si pr√©sentes
            if 'Vict Sex' in features_param:
                dummy_input['Vict Sex'] = [0]
            if 'Vict Descent' in features_param:
                dummy_input['Vict Descent'] = [0]
            if 'Premis Cd' in features_param:
                dummy_input['Premis Cd'] = [101.0]
            if 'Part 1-2' in features_param:
                dummy_input['Part 1-2'] = [1]
            
            # Inf√©rer la signature
            predictions = model.predict(dummy_input)
            signature = infer_signature(dummy_input, predictions)
            
            print(f"   ‚úÖ Signature cr√©√©e")
            
            # 4. Enregistrer dans MLflow
            print(f"\nüìù √âtape 4/4 : Enregistrement dans Model Registry...")
            
            with mlflow.start_run(run_name=f"promote_best_{run_id[:8]}"):
                # Copier les m√©triques importantes
                for metric in ['test_accuracy', 'test_f1_weighted', 'cv_accuracy_mean']:
                    value = original_run.data.metrics.get(metric)
                    if value is not None:
                        mlflow.log_metric(metric, value)
                
                # Copier les param√®tres
                for k, v in original_run.data.params.items():
                    mlflow.log_param(k, v)
                
                # Tags
                mlflow.set_tag("original_run_id", run_id)
                mlflow.set_tag("promoted_at", pd.Timestamp.now().isoformat())
                mlflow.set_tag("promotion_method", "auto_best_model")
                
                # Enregistrer le mod√®le
                mlflow.sklearn.log_model(
                    sk_model=model,
                    artifact_path="model",
                    signature=signature,
                    input_example=dummy_input,
                    registered_model_name=model_name
                )
            
            print(f"   ‚úÖ Mod√®le enregistr√© dans le Model Registry")
        
        # 5. R√©cup√©rer la nouvelle version
        latest_versions = client.get_latest_versions(model_name, stages=["None"])
        if not latest_versions:
            print("‚ùå Impossible de r√©cup√©rer la version cr√©√©e")
            return False
        
        new_version = latest_versions[0].version
        print(f"   ‚Üí Nouvelle version : v{new_version}")
        
        # 6. Archiver les anciennes versions en production
        print(f"\nüì¶ Archivage des anciennes versions...")
        prod_versions = client.get_latest_versions(model_name, stages=["Production"])
        for v in prod_versions:
            client.transition_model_version_stage(
                name=model_name,
                version=v.version,
                stage="Archived"
            )
            print(f"   ‚úì Version {v.version} archiv√©e")
        
        # 7. Promouvoir en production
        print(f"\nüöÄ Promotion en Production...")
        client.transition_model_version_stage(
            name=model_name,
            version=new_version,
            stage="Production"
        )
        
        # 8. Ajouter une description
        description = f"""
üèÜ Meilleur mod√®le s√©lectionn√© automatiquement parmi 6 mod√®les

üìä M√©triques :
   ‚Ä¢ Test Accuracy : {best_run_info['Test Accuracy']:.4f} ({best_run_info['Test Accuracy']*100:.2f}%)
   ‚Ä¢ Test F1-Score : {best_run_info['Test F1']:.4f}
   ‚Ä¢ CV Mean       : {best_run_info['CV Mean']:.4f}

üîß Configuration :
   ‚Ä¢ Type          : {best_run_info['Type']}
   ‚Ä¢ Model         : {best_run_info['Model']}
   ‚Ä¢ Run Name      : {best_run_info['Run Name']}

üìÖ Promotion :
   ‚Ä¢ Date          : {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
   ‚Ä¢ Run ID        : {run_id}
   ‚Ä¢ M√©thode       : Comparaison automatique des 6 mod√®les
        """.strip()
        
        client.update_model_version(
            name=model_name,
            version=new_version,
            description=description
        )
        
        print(f"\n" + "=" * 130)
        print("‚úÖ PROMOTION R√âUSSIE !")
        print("=" * 130)
        print(f"\nüéâ {model_name} v{new_version} est maintenant en PRODUCTION")
        print(f"\nüìç V√©rifiez sur DagsHub :")
        print(f"   https://dagshub.com/benrhoumamohamed752/ProjetMLOps")
        print(f"\nüí° Charger le mod√®le en production :")
        print(f"   import mlflow")
        print(f"   import dagshub")
        print(f"   dagshub.init(repo_owner='benrhoumamohamed752', repo_name='ProjetMLOps', mlflow=True)")
        print(f"   model = mlflow.pyfunc.load_model('models:/{model_name}/Production')")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erreur lors de la promotion : {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    parser = argparse.ArgumentParser(description='Comparer et promouvoir le meilleur mod√®le d\'une ann√©e')
    parser.add_argument('--year', type=str, required=True, help='Ann√©e √† analyser (ex: 2021)')
    parser.add_argument('--save', action='store_true')
    parser.add_argument('--top', type=int, default=None)
    parser.add_argument('--promote', action='store_true')
    parser.add_argument('--auto_promote', action='store_true')
    parser.add_argument('--model_name', type=str, default='crime-prediction-model')
    args = parser.parse_args()

    client = connect_to_mlflow()

    df = get_models_by_year(client, args.year)

    if df is None:
        return

    if args.top:
        df = df.head(args.top)

    display_comparison(df)
    display_top_3(df)
    display_best_model_details(client, df)
    display_statistics(df)

    if args.save:
        os.makedirs('reports', exist_ok=True)
        df.to_csv(f'reports/models_comparison_{args.year}.csv', index=False)
        print(f"\nüíæ Rapport sauvegard√© : reports/models_comparison_{args.year}.csv")

    recommend_action(df, args.year)

    if args.promote or args.auto_promote:
        best_model_info = df.iloc[0].to_dict()
        success = promote_best_model(
            client,
            best_model_info,
            model_name=args.model_name,
            auto=args.auto_promote
        )
        if success:
            print(f"\nMod√®le {args.year} promu en Production !")

    print("\n" + "=" * 130)
    print("‚úÖ COMPARAISON TERMIN√âE")
    print("=" * 130)

if __name__ == "__main__":
    main()